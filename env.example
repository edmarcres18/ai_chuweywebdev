# Ollama API Proxy Server Configuration
# Rename this file to .env and modify values as needed

# Server configuration
PORT=3000
NODE_ENV=development  # Set to 'production' for production deployment

# API endpoints
OLLAMA_API_LOCAL=http://192.168.1.50:11434/api/generate
OLLAMA_API_PRODUCTION=https://ollama.mhrpci.site/api/generate

# Security (uncomment and set if your API requires authentication)
# OLLAMA_API_KEY=your_api_key_here 

# Rate limiting
RATE_LIMIT_WINDOW_MS=60000  # 1 minute
RATE_LIMIT_MAX_REQUESTS=20  # 20 requests per window

# Logging configuration
LOG_LEVEL=info  # Options: error, warn, info, debug 